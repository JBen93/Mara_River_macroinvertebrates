---
title: "Importing data into R"
author: "Han Olff"
format: html
date: "2024-08-31"
---

# Importing data in R

Data can be imported in different ways in R:\
1. entering data directly in your script\
2. reading data from a .csv or .xlsx file from your local computer or online source\
3. reading data from a published csv link in a Google Sheets database\
We will mostly use the last method during this course. When reading data, we prefer the readr::read_csv() function, as it reads data directly into a tibble instead of a dataframe. A tibble is more compact when printed and shows the variable types directly.

### 1. enter data in your script

```{r}
#| label: load-libraries
#| output: false  
library(tidyverse) # load the tidyverse libraries, including readr
```


```{r}
#| label: enter-data-in-script
#| warning: false
# method 1 - data enter by typing them into your your script 
x<-c(1,2,3,4)
y<-c(1,4,3,5)
data1<-data.frame(x,y)
print(data1)

```

### 2. Read data from a local file

Entering data through your script is however not practical for large datasets, then it is better to read data from a file.\
If you want to read a file from a drive from your computer, it is a good idea to set a working directory to point where your different datasets are located

```{r}
#| label: read-from-disk
# setwd("C:/Users/holff/data") # note that the slashes have to be forward, not backward
# data2<-readr::read_csv("EVI2001_2023.csv")
# print(data2)
```

The problem however, is that this script likely does not work on your computer when you would remove # in front of each line. This is because you do not have this file and folder on your local computer. I can of course send you the data, but then if I change the I should send them again. This leads to different versions of the same file to exist in multiple places, which is not good data management. You will not be shure what the most up-to-dat version of the file is. So in collaborative projects it is much better to read data from an online data source, making sure that there is only one file that all the collaborators read to get the data.\

### 3. Read data directly from an online database

This is the recommended methods of these three. The data are in one online database.

#### 3.1. Working with Google Drive

Your @rug.nl or @student.rug.nl account is also a Google Account.

#### 3.2 Google Sheets as an online database

I recommend to use Google Sheets as your database management system. Google Sheets is a spreadsheets program, similar to Microsoft Excel. Google Sheets files "live" in the cloud associated with your Google account. As they are a spreadsheet program they are not formally database software. But a Google Sheets document can be set up quite well as a 'lightweight' relational database. When done well according to a couple of clear principles (as described here),

Google Sheets can also be set up to publish online tables in such a database to a .CSV (Comma Separated Values ascii text) file, that can be directly read into R. For this use in Google Sheets menu File/ Share / Publish to web, choose the sheet to publish andas type, choose Comma-separated values. This produces a link, that you put in your R script. This is the preferred methods, as it comes with large benefits of managing the data in one place in a relational database. It is best practice to give the dataframe that you read in R the same name as the table (sheet) in Google Sheets. In this way, data can be read on any computer, and multiple computers can read the same datafile. That is what you want in a collaborative project.

I will further explain this using this examples file [ExampleDatabase_CensusTransects_Fredy_Milenka.gsheet](https://docs.google.com/spreadsheets/d/1m-liu8omZMewqz_YP9j_YUmQ0zwATl3z4aRLnZFnfWc/edit?usp=sharing).

This is a Google Sheets database that only exists in one location in the cloud. It is set to "Anyone with the link can view", while one particular people can edit this. This access can be controlled on the level of individual users, who can view (can also be only specific people) and who can edit the file. The file is organised as a relational database using a Star Schedule. The different sheets in the file are called tables.

#### 3.3 Star Schema data organisation

This example organized as a Star Schema database, explained in detail in [this document](https://docs.google.com/document/d/1UbUMVFfF4muRqt_YOT73NT7xt-vsoLHs0xNza_Le56U/edit?usp=sharing). This is a particular type of organisation of data into a relational database using Dim and Fact tables. In addition I also recommend Met tables. These **Met tables** contains documents, 'data about data'. **Dim tables** contain information on lists of objects and subjects that you study in your project with their properties. **Fact tables** are the data that you collect on the objects or subjects listed in your Dim tables.

##### 3.3.1 Met tables

Met tables contain meta-data, documenting the other data in the database. I recommend to use the following tables in your database, where it helps to always use Met tables names in your different database, as shown in this [example database](https://docs.google.com/spreadsheets/d/1m-liu8omZMewqz_YP9j_YUmQ0zwATl3z4aRLnZFnfWc/edit?usp=sharing): + MetStudyInfo: short descriptions of the key features of your study, such as primary invstigator, starting date.\
+ MetStill2Do: list of what you still need to do, your ToDo list forthe database, as enter data, check something still in your field book, etc. In this table, keep track of who will do it of your team, in which table, for which variable and put a date when it is complete. + MetTables: the list of tables (sheets) in your database, with for each table a short contents description and a CSV link to read the table in an R script. This link for each table you produce from the menu File /Share /Publish to web and then selecting the table name (instead of entire document) and Comma separated values (instead of Web page). This then shows the link. If you put this link in your browser, it gives a download as a csv file. But you can also use this link directly in R to read the data using readr::read_csv(link). So this avoids the use of intermediary data files. Anyone with a script containing that link can read the data. Because such links are impossible to guess this is still sufficiently safe for regular ecological data. If you however want additional security, you can also set up access to tables using the google_drive package in R, allowing user authentication.\

##### 3.3.2 Dim tables

Dimension tables contain lists of objects or subjects that you collect data for in your database, such as the list of plots, locations, sites, species, treatments etc. They are typically part of your study design. Each Dim table starts with an \_ID variable, also called the key variable, where the value of this variable **should be unique** for each row. This is needed for the relational database aspect, to make clear how the information relates between tables. Dim tables are typically filled when designing your study so before starting your data collection. They typically do not get longer during the data collection phase in the project. Each Dim table contains the different properties of each object and subject used in the study. For example, check out this table [DimTransect](https://docs.google.com/spreadsheets/d/1m-liu8omZMewqz_YP9j_YUmQ0zwATl3z4aRLnZFnfWc/edit?gid=801890265#gid=801890265). This particular study consists of 18 transects, where the DimTransect tables defines the unique properties of to each transects, such as its start and end coordinates, the general study area where a transect is located, and in which country (Tanzania or Kenya in this case). So it is part of the study design. The first variable (column) is Along each transects, wildlife was counted in this case,

##### 3.3.3 Fact tables

Fact tables contain the actual data that are collected on the different transects.

#### 3.4 Example

```{r}
#| label: read-google-sheets-data

FactSectionAnimals_link<-"https://docs.google.com/spreadsheets/d/1m-liu8omZMewqz_YP9j_YUmQ0zwATl3z4aRLnZFnfWc/pub?gid=1286117256&single=true&output=csv"
FactSectionAnimals<-read_csv(FactSectionAnimals_link)
```

This loads the dataset directly from Google Sheets into R, there are not intermediate files. If they data change in Google Sheets, then the new version will be loaded when the @read-google-sheet-data code is run again.

```{r}
#| label: fig-boxplot
#| fig-cap: Boxplot of the number of individuals observed for each species. 

ggplot(data=FactSectionAnimals, 
       mapping=aes(x=Name_eng,y=CountLeft)) +
  geom_boxplot()
```
