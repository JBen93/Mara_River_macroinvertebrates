---
title: "ERS Course_University of Groningen"
author: "Joshua Benjamin"
date: "2024-09-03"
format: html
editor: 
  markdown: 
    wrap: 72
    editor_options:
      chunk_output_type: onsole
  chunk_output_type:console
---

# Using renv for making R predictable adapted from Han Olff
A major strength, but also potential challenge of R is that the software changes all the time. All functionality of R comes from packages, and these are improved, expanded, updated all the time. Say that you develop a set of scripts in R now, for example to analyse the data in your master project., and you develop a publication from the results. But you get several revisions, and finally complete the paper two years later. By that time, you will have updated your versions of R and your packages several times.This may change the functionality of your scripts, they may not work anymore. And when you publish the paper and deposit the data and scripts in a repository, even 10 years from now you want to be able to replicate your analyses, with the "old" versions of the packages that you used at the time when you did the analysis for the paper.

A similar problem works when working on scripts and data in a collaborative project with multiple people. Then typically, not every every collaborator will have exactly the same packages and samve versions of the same package installed in their R library. This means only one person can improve the scripts and run them, instead of everyone contributing.

The renv package solves this in combination with using an R Studio project and Git/Github. You use it to create an renv.lock file with renv::init(). You typically only do this once. This initialization of your project serves two goals:\
\* new packages are installed from then on in a library in the local folder of your project, not anymore in your general R installation. So the packages "belong" to the project\
\* you, or your collaborators, can use renv::restore() to create now or later exactly the same R library (same versions of the packages) as you are using to develop the scripts, where these version numbers are read from the renv.lock file. If certain packages are not installed yet on that specific computer, they will be installed.

#Here is how to use restore:

```{r}
#| label: restore-all-package-versions
renv::restore() # restore your libraries from the lock file
```

# Working with Quarto documents in R

### 1. Benefits of using Quarto over regular R scripts

Working with Quarto has a range of benefits:

-   Using its headers creates an automated outline of your script (see
    pane to the right), this helps in navigating arround in your script
-   You can mix regular text with R script, for example to introduce the
    philosophy or assumptions of a particular analysis, and/or to
    summarize the conclusions that you draw from the analysis
-   formatting of headers, tables, figure captions etc is
    near-automatic, you hardly need to think about it
-   it's code chunks forces you to work in a more modular way when
    developing a script, step by step, task by task
-   the rendered output documents are very nice, can be ready to go as a
    report or publication, even a whole book
-   rendered output can be in all kinds of formats, like docx, pdf,
    html + it integrates very well with generating content for the
    internet
-   a quarto document is easy to ready even for a normal person ðŸ˜Š

### 2. Markdown, R Markdown and Quarto

Markdown is a lightweight markup language used to format plain text in a
simple, human-readable way. It is a simple way to format headers, tables
etc for still a simple text document, such as this text, using plain
text formatting. Files have the .md extension. For example, the '\#' in
front of the first line of this document indicates that it is a title,
and needs to be formatted like that. If you switch this window of this
text to the tab "visual" you see what happens. Markdown is lightweight
eg compared to html (how most internet pages are written), which allows
much more formatting, and makes files practically not readable anymore
with a regular text editor.

Later, Markdown was expanded to R Markdown, which allows to use Markdown
in the context of an R Script. Files have the .Rmd extension. This
allows the alternation of regular text (such as this) with so-called
code-chunks of R script. It allows you to not only write a script, but
also directly in the script explain why you do things a certain way, and
what the result means.

The latest development in this regard is the development of Quarto. It
is an open-source scientific and technical publishing system that allows
you to create high-quality documents, presentations, websites, blogs,
and more using a combination of code, text, and visualizations. It's
designed to be a next-generation tool for literate programming,
reproducible research, and data science, similar to R Markdown but more
flexible and language-agnostic. This document is written in Quarto. It
allows the combination of R script with regular text and figures. So it
is great to explain what you are going to do in a script, and to write
an interpretation of our output. This way, a quarto file with script is
already halfway a scientific report. You can even write a whole paper or
book in Quarto, including all the data analysis that is included in it.
A strong point is that you can even mix languages.

See this [overview of markdown
basics](https://quarto.org/docs/authoring/markdown-basics.html) as used
in Quarto. It also supports the use of
[citations](https://quarto.org/docs/authoring/citations.html). It can
use references in a BibText format. Such a file you can export from most
reference managers. I recommend to use [Zotero](https://www.zotero.org/)
for managing your citations, see how to [export to
BibTex](https://libguides.rhul.ac.uk/referencing/Zoterolatex) from
Zotero.

### 3. Run a (chunk of) R script

A script part in a Quarto document is called a chunk. It starts with
indicating in which language it is written, then some execution options
starting with #\| and then the script itself. This code chunk can be run
as a block of code by using the small green arrow at the top right.

```{r}
# define a variable A and assign a value 5 to it
A <- 5
#same for variable B
B <- 10
#calculate the sum of A and B
C <- A + B
# print the result
print(C)
#caculate the mean of the numbers 1, 3,7,12,46
my_numbers <- c(1, 3, 7, 12, 46)
mean(my_numbers)


```

#make a figure


```{r}

library(tidyverse)
# set the seed of the random number generator (gives same result)
set.seed(123)
# generate 100 random values form a normal distribution with mean=0 and standard deviation 1
randomvalue <- rnorm(n = 100, mean = 0, sd = 1)
print(randomvalue)
mean(randomvalue)

# convert to a dataframe
data1<-data.frame(randomvalue)
data1
# plot as a histogram with axis labels
ggplot2::ggplot(data=data1, 
                mapping=aes(x=randomvalue)) +
  geom_histogram()

```
```{r}
 #Importing data in R

#Data can be imported in different ways in R:\
1. entering data directly in your script\
2. reading data from a .csv or .xlsx file from your local computer or online source\
3. reading data from a published csv link in a Google Sheets database\
We will mostly use the last method during this course. When reading data, we prefer the readr::read_csv() function, as it reads data directly into a tibble instead of a dataframe. A tibble is more compact when printed and shows the variable types directly.
```

### 1. enter data in your script

```{r}
#| label: load-libraries
#| output: false  
library(tidyverse) # load the tidyverse libraries, including readr
```

```{r}
#| label: enter-data-in-script
#| warning: false
# method 1 - data enter by typing them into your your script 
x<-c(1,2,3,4)
y<-c(1,4,3,5)
data1<-data.frame(x,y)
print(data1)

```

### 2. Read data from a local file

Entering data through your script is however not practical for large datasets, then it is better to read data from a file.\
If you want to read a file from a drive from your computer, it is a good idea to set a working directory to point where your different datasets are located

```{r}
#| label: read-from-disk
# setwd("C:/Users/holff/data") # note that the slashes have to be forward, not backward
# data2<-readr::read_csv("EVI2001_2023.csv")
# print(data2)
```

The problem however, is that this script likely does not work on your computer when you would remove # in front of each line. This is because you do not have this file and folder on your local computer. I can of course send you the data, but then if I change the I should send them again. This leads to different versions of the same file to exist in multiple places, which is not good data management. You will not be shure what the most up-to-dat version of the file is. So in collaborative projects it is much better to read data from an online data source, making sure that there is only one file that all the collaborators read to get the data.\

### 3. Read data directly from an online database

This is the recommended methods of these three. The data are in one online database.

#### 3.1. Working with Google Drive

Your @rug.nl or @student.rug.nl account is also a Google Account.

#### 3.2 Google Sheets as an online database

I recommend to use Google Sheets as your database management system. Google Sheets is a spreadsheets program, similar to Microsoft Excel. Google Sheets files "live" in the cloud associated with your Google account. As they are a spreadsheet program they are not formally database software. But a Google Sheets document can be set up quite well as a 'lightweight' relational database. When done well according to a couple of clear principles (as described here),

Google Sheets can also be set up to publish online tables in such a database to a .CSV (Comma Separated Values ascii text) file, that can be directly read into R. For this use in Google Sheets menu File/ Share / Publish to web, choose the sheet to publish andas type, choose Comma-separated values. This produces a link, that you put in your R script. This is the preferred methods, as it comes with large benefits of managing the data in one place in a relational database. It is best practice to give the dataframe that you read in R the same name as the table (sheet) in Google Sheets. In this way, data can be read on any computer, and multiple computers can read the same datafile. That is what you want in a collaborative project.